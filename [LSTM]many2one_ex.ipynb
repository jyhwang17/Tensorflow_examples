{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE\n",
      "    userId  age  sex        date  dayofweek  amount  geoId  catId\n",
      "0        0   26    0  2018-01-01          0     2.5      3      4\n",
      "1        0   26    0  2018-01-01          0     2.5      3      8\n",
      "2        0   26    0  2018-01-01          0     2.5      1      2\n",
      "3        0   26    0  2018-01-02          0     3.5      7      3\n",
      "4        0   26    0  2018-01-02          0     2.5      8      4\n",
      "5        0   26    0  2018-01-04          0     4.0      9      5\n",
      "6        0   26    0  2018-01-05          0     0.5      1      1\n",
      "7        1   27    0  2018-02-01          0     2.1      1      1\n",
      "8        1   27    0  2018-02-01          0     1.6      1      2\n",
      "9        1   27    0  2018-02-01          0     0.3      1      3\n",
      "10       1   27    0  2018-02-02          0     0.1      1      4\n",
      "11       1   27    0  2018-02-03          0     1.1      1      5\n",
      "12       1   27    0  2018-02-03          0     2.3      1      6\n",
      "13       1   27    0  2018-02-04          0     2.1      2      7\n",
      "14       1   27    0  2018-02-05          0     2.0      3      8\n"
     ]
    }
   ],
   "source": [
    "direc=os.path.dirname(os.path.realpath('__file__'))\n",
    "os.path.join(direc)\n",
    "table = pd.read_csv(\"cat_prediction_train_ex.csv\", names=['userId','age','sex','date','dayofweek','amount','geoId','catId'])\n",
    "table.sort_values(by='date')\n",
    "print ('TABLE')\n",
    "print table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            userId  age  sex  dayofweek  amount  geoId  catId\n",
      "date                                                         \n",
      "2018-01-01       0   26    0          0     2.5      3      4\n",
      "2018-01-01       0   26    0          0     2.5      3      8\n",
      "2018-01-01       0   26    0          0     2.5      1      2\n",
      "2018-01-02       0   26    0          0     3.5      7      3\n",
      "2018-01-02       0   26    0          0     2.5      8      4\n",
      "2018-01-04       0   26    0          0     4.0      9      5\n",
      "2018-01-05       0   26    0          0     0.5      1      1\n",
      "2018-02-01       1   27    0          0     2.1      1      1\n",
      "2018-02-01       1   27    0          0     1.6      1      2\n",
      "2018-02-01       1   27    0          0     0.3      1      3\n",
      "2018-02-02       1   27    0          0     0.1      1      4\n",
      "2018-02-03       1   27    0          0     1.1      1      5\n",
      "2018-02-03       1   27    0          0     2.3      1      6\n",
      "2018-02-04       1   27    0          0     2.1      2      7\n",
      "2018-02-05       1   27    0          0     2.0      3      8\n"
     ]
    }
   ],
   "source": [
    "table['date'] = pd.to_datetime(table['date'], format='%Y-%m-%d')\n",
    "table = table.set_index(['date'])\n",
    "print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            userId  age  sex  dayofweek    amount  geoId  catId\n",
      "date                                                           \n",
      "2018-01-01       0  0.0    0          0  0.615385      3      4\n",
      "2018-01-01       0  0.0    0          0  0.615385      3      8\n",
      "2018-01-01       0  0.0    0          0  0.615385      1      2\n",
      "2018-01-02       0  0.0    0          0  0.871795      7      3\n",
      "2018-01-02       0  0.0    0          0  0.615385      8      4\n",
      "2018-01-04       0  0.0    0          0  1.000000      9      5\n",
      "2018-01-05       0  0.0    0          0  0.102564      1      1\n",
      "2018-02-01       1  1.0    0          0  0.512821      1      1\n",
      "2018-02-01       1  1.0    0          0  0.384615      1      2\n",
      "2018-02-01       1  1.0    0          0  0.051282      1      3\n",
      "2018-02-02       1  1.0    0          0  0.000000      1      4\n",
      "2018-02-03       1  1.0    0          0  0.256410      1      5\n",
      "2018-02-03       1  1.0    0          0  0.564103      1      6\n",
      "2018-02-04       1  1.0    0          0  0.512821      2      7\n",
      "2018-02-05       1  1.0    0          0  0.487179      3      8\n"
     ]
    }
   ],
   "source": [
    "#min-max scaling \n",
    "epsilon = 0.00000000001\n",
    "table['age'] =    ( table['age'] - table['age'].min() ) /( table['age'].max()-table['age'].min()+epsilon)\n",
    "table['amount'] = ( table['amount'] - table['amount'].min()) / (table['amount'].max()-table['amount'].min() +epsilon )\n",
    "print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         1.84615385 1.         0.         1.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   1.         0.         1.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         1.\n",
      "   0.         1.         0.         0.         0.         1.\n",
      "   0.        ]\n",
      "  [0.         1.48717949 1.         0.         1.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   1.         1.         0.         0.         0.         0.\n",
      "   1.         1.         0.         0.         0.         0.\n",
      "   0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.        ]]\n",
      "\n",
      " [[1.         0.94871795 1.         0.         1.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   1.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         1.         1.\n",
      "   1.         0.         0.         0.         0.         0.\n",
      "   0.        ]\n",
      "  [1.         0.         1.         0.         1.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   1.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         1.         0.         0.         0.         0.\n",
      "   0.        ]\n",
      "  [1.         0.82051282 1.         0.         1.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   1.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         1.         1.         0.         0.\n",
      "   0.        ]]]\n",
      "[[[0.        ]\n",
      "  [1.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.51282051]]]\n",
      "[2 3]\n",
      "[[[0.]\n",
      "  [1.]\n",
      "  [0.]]\n",
      "\n",
      " [[0.]\n",
      "  [0.]\n",
      "  [1.]]]\n"
     ]
    }
   ],
   "source": [
    "#Convert batch\n",
    "from datetime import datetime\n",
    "\n",
    "def timeTuple():\n",
    "    tp = [('2018-01-01','2018-01-03','2018-01-04','2018-01-04'),\n",
    "          \n",
    "          ('2018-02-01','2018-02-03','2018-02-04','2018-02-04')\n",
    "          \n",
    "          ]            \n",
    "    return tp\n",
    "\n",
    "\n",
    "userList = [0,1]\n",
    "\n",
    "def df2seq(df,userList,params):\n",
    "    \n",
    "    #dataframe to Sequence\n",
    "    #[many2one Sequence maker]\n",
    "    \n",
    "    maxLen = params['maxLen']\n",
    "    categoryCount = params['categoryCount']\n",
    "    geoCount = params['geoCount']\n",
    "    \n",
    "    tp = timeTuple()\n",
    "    \n",
    "    seq_train=[] # (batch,maxLen,input_size)\n",
    "    seq_label=[] # (batch,1) \n",
    "    seq_len=[] # (batch)\n",
    "    seq_mask=[]\n",
    "    \n",
    "    for user in userList:\n",
    "        userHistory = df.groupby(['userId']).get_group((user))\n",
    "        \n",
    "        for input_s,input_e, output_s,output_e in tp:\n",
    "            \n",
    "            #check-ins summarization based on day\n",
    "            \n",
    "            example = userHistory.loc[input_s:input_e]\n",
    "            answer = userHistory.loc[output_s:output_e]\n",
    "            \n",
    "            input_s = pd.Timestamp(input_s)\n",
    "            output_s= pd.Timestamp(output_s)\n",
    "            if not example.empty and not answer.empty:\n",
    "                \n",
    "                train_window = example.groupby('date')\n",
    "                infer_window = answer.groupby('date')\n",
    "                \n",
    "                cont_features = np.zeros((maxLen,2))\n",
    "                sex_features = np.zeros((maxLen,2))\n",
    "                week_features= np.zeros((maxLen,7))\n",
    "                geo_features = np.zeros((maxLen,geoCount))\n",
    "                category_features = np.zeros((maxLen,categoryCount))\n",
    "                \n",
    "                mask = np.zeros((maxLen,1))\n",
    "                label = np.zeros((maxLen,1))\n",
    "                \n",
    "                LastDay=0\n",
    "                \n",
    "                for date,info in train_window:\n",
    "                    day = (date-input_s).days\n",
    "                    \n",
    "                    LastDay = max(LastDay,day)\n",
    "                    \n",
    "                    age = float(info.agg({'age':'unique'})['age'])\n",
    "                    amount = float(info.agg({'amount':'sum'})['amount'])\n",
    "                    \n",
    "                    sex = int(info.agg({'sex':'unique'})['sex'])\n",
    "                    dayofweek = int(info.agg({'dayofweek':'unique'})['dayofweek'])\n",
    "                    \n",
    "                    geoList = np.array(info.agg({'geoId':'unique'})['geoId'])\n",
    "                    catList = np.array(info.agg({'catId':'unique'})['catId'])\n",
    "                    \n",
    "                    cont_features[day][0] = age\n",
    "                    cont_features[day][1] = amount\n",
    "                    \n",
    "                    sex_features[day][sex]=1\n",
    "                    week_features[day][dayofweek]=1\n",
    "                    \n",
    "                    geo_features[day][geoList]=1\n",
    "                    geo_features[day][0]=0\n",
    "                    \n",
    "                    category_features[day][catList]=1\n",
    "                    category_features[day][0]=0\n",
    "                \n",
    "                for date,info in infer_window:\n",
    "                    amount = float(info.agg({'amount':'sum'})['amount'])\n",
    "                    label[LastDay]+=amount\n",
    "                    \n",
    "                \n",
    "                cont_features = np.array(cont_features)\n",
    "                sex_features = np.array(sex_features)\n",
    "                week_features= np.array(week_features)\n",
    "                geo_features = np.array(geo_features)\n",
    "                category_features = np.array(category_features)\n",
    "                \n",
    "                sequence = np.zeros((maxLen,0))\n",
    "                sequence = np.concatenate((sequence,cont_features),axis=1)\n",
    "                sequence = np.concatenate((sequence,sex_features),axis=1) \n",
    "                sequence = np.concatenate((sequence,week_features),axis=1)\n",
    "                sequence = np.concatenate((sequence,geo_features), axis=1)\n",
    "                sequence = np.concatenate((sequence,category_features),axis=1)\n",
    "                \n",
    "                mask[LastDay]=1\n",
    "                \n",
    "                seq_train.append(sequence)\n",
    "                seq_label.append(label)\n",
    "                seq_mask.append(mask)\n",
    "                seq_len.append(LastDay+1)\n",
    "                \n",
    "                \n",
    "    return np.array(seq_train),np.array(seq_label),np.array(seq_mask),np.array(seq_len)\n",
    "\n",
    "\n",
    "userList = [0,1]\n",
    "params={}\n",
    "params['maxLen'] = 3  #3일치\n",
    "params['categoryCount']=10\n",
    "params['geoCount']=10\n",
    "\n",
    "params['input_size'] = 2+2+7+params['geoCount']+ params['categoryCount']\n",
    "\n",
    "seq_train,seq_label,seq_mask,seq_len= df2seq(table,userList,params)\n",
    "\n",
    "print seq_train\n",
    "print seq_label\n",
    "print seq_len\n",
    "print seq_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss[0/10]:0.16775988\n",
      "Loss[1/10]:0.08688108\n",
      "Loss[2/10]:0.04376262\n",
      "Loss[3/10]:0.027055169\n",
      "Loss[4/10]:0.020529136\n",
      "Loss[5/10]:0.017486563\n",
      "Loss[6/10]:0.01525775\n",
      "Loss[7/10]:0.012896835\n",
      "Loss[8/10]:0.010182167\n",
      "Loss[9/10]:0.0072484515\n"
     ]
    }
   ],
   "source": [
    "max_len = params['maxLen']\n",
    "input_size = params['input_size']\n",
    "\n",
    "#define lstm\n",
    "sequence = tf.placeholder( tf.float32, [None, max_len, input_size ])\n",
    "labels = tf.placeholder( tf.float32, [None,max_len,1]) \n",
    "#weights= tf.ones([None])\n",
    "\n",
    "dynamic_length= tf.placeholder(tf.int32, [None])\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units = 1)\n",
    "\n",
    "outputs,_ = tf.nn.dynamic_rnn(cell, sequence , dtype=tf.float32, sequence_length = dynamic_length)\n",
    "\n",
    "predictions = outputs*seq_mask\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(labels-predictions))\n",
    "train = tf.train.AdamOptimizer(learning_rate= 0.051).minimize(loss)\n",
    "\n",
    "epochs=10\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for it in range(epochs):\n",
    "        l,_ = sess.run([loss,train],feed_dict={sequence: seq_train,\n",
    "                                          labels:seq_label,\n",
    "                                          dynamic_length:seq_len} )\n",
    "\n",
    "        print (\"Loss[%s/%s]:%s\"%(it,epochs,l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
